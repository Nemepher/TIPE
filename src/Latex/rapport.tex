\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{pgf}
\usepackage{pgfplots}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[nottoc]{tocbibind}

\pagestyle{headings}
\pgfplotsset{width=5cm,compat=1.16}
\captionsetup{font=footnotesize}

\title{Détection et identification d'arbre à partir d'imagerie satellite}
\author{Augustin Albert}

\begin{document}

\maketitle
\tableofcontents

\section*{Introduction}

L'étude et le suivi de la répartition des espèces au sein de larges zones forestières est un problème complexe aux applications nombreuses :
gestion des ressources naturelles, protection de la biodiversité, etc... Les études de terrain peuvent se révéler longues, coûteuses et imprécises du à la nécessité d'interpoler les données recueillies. 
Parvenir à automatiser ce processus est donc un enjeu critique. 

Les techniques existantes reposent sur l'utilisation de données satellite ou aériennes : L'utilisation d'images est une méthode peu coûteuse nécessitant peu de materiel et pas d'intervention sur le terrain lorsque 
des images satellites récentes de résolution suffisantes, qui deviennent de plus en plus accessible.  

UAV LIdar -> methodes plus simples qui ne requierent que des images st HR. Différentes méthodes existent, detection de blob ? LoG

Intro: Méthode naive ( les preentations) de detection des zones plus lumineuses. La luminosité des arbres peut beaucoup varier sur une meme image (à moins d'avoir des images de haute qualité "prise en une seule fois" (ex papier). Une solution = Détection de blobs. 2 problemes : -différence de luminosité et différence d'échelle. Citer algo pour. de pixels plus lumineux que leur voisins correspondants aux houppiers


\subsection*{Objectifs du TIPE}		
\begin{enumerate}
	\item implementer un algorithme de détection et de délimitation de houppiers (Cime d'arbres) basé sur des images satellites de resolution "moyenne" à l'aide de la théorie de l'Espace d'échelle (« Scale-space ») 
	\item entraîner un reseau neurone à l'aide de la bibliothèque Tensorflow afin d'identifier des espèces à partir d'images de houppiers de basse résolution 
	\item appliquer ces derniers au parc ... présentant une variété d'espèces et des paternes plus ou moins réguliers pour confronter les résultats obtenus aux données de terrain et aux techniques existantes.    
\end{enumerate}
	
		-limitation à des images aériennes: pourquoi(moins coûteux, accessible sur internet, différents modes d'acquisitions,  enjeux/difficultés
		-d'une part à concevoir ... pour detecter les a
		-d'autre part à l'utiliser pour construire une base de donné permettant identification ultérieure sur la base du machin learning
		-application au site du parc regional...
		
	
\section{Détection des houppiers}

	\subsection{Laplacien du gaussien et approche multi échelle}
	+dectection de blobs
	Le problème de Afin de prendre en compte des houppiers dont le diamètre peut varier considérablement entre les différentes espèces mais aussi au sein d'une même espèce, une approche multi-échelle est nécessaire. Nous utiliserons la théorie échelle-temps développée par (\ref Lindbergh). 
	
	Celle-ci consiste à lisser l'image original de manière répété pour générer une pyramide d'échelle qui sera exploitée ultérieurement. L'image originelle est lissée et éventuellement sous-échantillonnée autant de fois que nécessaire au moyen d'un filtre gaussien dont le paramètre d'échelle $\sigma$ est multiplié à chaque étape par un ratio fixe. ( Voir~\ref{fig:ex} ) Cela revient à convoler l'image par la fonction gaussienne suivante : 
	
	\[G_{\sigma}:=\frac{1}{2\pi\sigma^{2}}\exp(-\frac{x^{2}+y^{2}}{2\sigma^{2}})\]

	Dans la littérature, ce ratio est 2. Puisque la taille de l'image est réduite de moitié à chaque étape, chaque niveau est appelé octave en référence à la théorie musicale. Il peut être intéressant de rajouter des intervalles supplémentaires, ce qui est fait dans la suite. 
	On dispose donc de 3 paramètres: $\sigma$, le nombre d'octave o et le nombre d'intervalle pour chaque octave i. La hauteur ( nombre de niveau de la pyramide ) est alors $o \times i$ et le ratio $2^{\frac{1}{i}}$. 

	On applique alors un opérateur laplacien normalisé aux images résultante afin d'obtenir la pyramide d'échelle du laplacien du Gaussien ( "LoG" ). L'image obtenue à chaque niveau est alors la convolution de l'image originelle par la fonction Log :

	\[{LoG}_{\sigma}:=-\frac{1}{\pi\sigma^{4}}(1-\frac{x^{2}+y^{2}}{2\sigma^{2}})\exp(-\frac{x^{2}+y^{2}}{2\sigma^{2}})\] 

	En pratique, le LoG est approximé par la différence du gaussien ( "DoG" ) obtenue en réalisant la difference des images floutées entre chaque niveau de la pyramide d'échelle. (D'ou la nécessité de ne pas sous échantillonner les images intermédiaires pour qu'elles conservent la même dimension)

	La pyramide d'échelle de l'opérateur LoG permet d'extraire des caractéristiques indépendamment de leur échelle en exploitant la réponse de l'opérateur LoG appliqué à un signal échelon. ( Voir~\ref{fig:graph} ). Lorsque le rayon caractéristique du blob $r$ varie, le minimum (maximum en valeur absolue) du LoG est atteint au centre du blob. Lorsque le paramètre $\sigma$ varie, la réponse au centre est minimale lorsque $r$ est relié à $\sigma$ par la relation $\sigma=\frac{r}{\sqrt{2}}$. La réponse du LoG non normalisé s'attenuant lorsque $\sigma$ augmente, l'opérateur est multiplié par $\sigma^{2}$ pour que la réponse soit indépendante de l'échelle.

	La détection des blobs se ramène ainsi à la recherche d'un minimum local relativement à l'espace et global relativement à l'échelle pour identifier à la fois les centres des houppiers et la taille caractéristique de leur rayon. 

\begin{figure}
	\centering
	\includegraphics[scale=0.15]{img.png}
	\caption{Example de pyramide d'image, Original, CC BY-SA 1.0}
	\label{fig:ex}
\end{figure}

\begin{figure}
	\begin{subfigure}{.5\textwidth}
		\scalebox{0.3}{\input{fig1.pgf}}
		\caption{Réponse à une marche}
	\end{subfigure}
	\begin{subfigure}{.5\textwidth}
		\scalebox{0.3}{\input{fig2.pgf}}
		\caption{Réponse à un créneau pour $\sigma=1$, $\sigma=2$ et $\sigma=3$ }
	\end{subfigure}
	\begin{subfigure}{.5\textwidth}
		\scalebox{0.3}{\input{fig3.pgf}}
		\caption{Réponses à des créneaux pour $\sigma=1$}
	\end{subfigure}
	\caption{Réponse de l'opérateur LoG à différents signaux}
	\label{fig:graph}
\end{figure}


	\subsection{Mise en place de l'algorithme}

	
\begin{figure}
	\centering
	\begin{tikzpicture}[scale=.6]
		\draw [<-, > = angle 90, line width=0.3mm, black] (-4, 8) -- (-4, 3);
		\node[align=left] at (-2.75,7.75) {échelle};
		\begin{scope}[yslant=0.5, xslant=-1]
			\fill[step=5mm, blue] (2,1.5) rectangle (3.5,3);
			\draw[step=5mm, black] (1,1) grid (4,4);
			\draw[step=5mm, thick, black] (1,1) rectangle (4,4);
		\end{scope}
		\begin{scope}[yshift=50, yslant=0.5, xslant=-1]
			\fill[step=5mm, white] (1,1) rectangle (4,4);
			\fill[step=5mm, blue] (2,1.5) rectangle (3.5,3);
			\fill[step=5mm, red] (2.5,2) rectangle (3,2.5);
			\draw[step=5mm, black] (1,1) grid (4,4);
			\draw[step=5mm, thick, black] (1,1) rectangle (4,4);
		\end{scope}
		\begin{scope}[yshift=100, yslant=0.5, xslant=-1]
			\fill[step=5mm, white] (1,1) rectangle (4,4);
			\fill[step=5mm, blue] (2,1.5) rectangle (3.5,3);
			\draw[step=5mm, black] (1,1) grid (4,4);
			\draw[step=5mm, thick, black] (1,1) rectangle (4,4);
		\end{scope}
		\end{tikzpicture}
	\caption{Calcul des minimums dans la pyramide d'échelle de l'opérateur DoG}
	\label{fig:sche}
\end{figure}


	L'algorithme envisagé à été implémenté à l'aide du langage Python et utilise la bibliothèque Numpy afin d'accélérer le traitement des tableaux. Son fonctionnement est le suivant:

	\begin{enumerate}
	\item L'image à traiter est convertie en nuance de gris et éventuellement inversée afin que le fond soit plus clair que les houppiers. (une intervention humaine est nécessaire). 
	\item La pyramide d'échelle de l'opérateur DoG est générée et stockée dans un tableau Numpy à 3 dimension. Les noyaux de Gauss et la convolution ont été implémenté en exploitant la séparabilité du filtre de Gauss pour accélérer le calcul mais en définitive la convolution fourni par le module Scipy à été utilisée.  
	\item En pratique, différentes détection peuvent avoir lieu dans la même colonne. Le maximum relatif à l'échelle devient alors local et des multiples détections n'est conservé que celle de rayon caractéristique maximal. 
	Les minimums sont donc calculé en parcourant le tableau par échelle décroissante ( Du plus flouté au moins flouté ) afin de ne conserver que les houppiers de rayon maximum lors d'éventuels chevauchements. Chaque case du tableau étant comparée à ses 26 voisins uniquement ( Voir~\ref{fig:sche} ) 
	\end{enumerate}

	3 paramètres permettent d'ajuster les résultats. La sélection des paramètres dépend fortement du (très heuristique comme méthode, nécessite des essais => la méthodes n'est pas completement automatique. (dépend de la taille caractéristique des arbres, de l'echelle choisie) donner les paramètre pour l'echelle et tout.

		facteur limitant i
		choix final des paramètres : + image utilisées (taille des arbres sur le terrain et échelle de l'image) 


\section{Identification des espèces}

	L'identification d'espèce est un problème de reconnaissance de forme ( "pattern recognition" ) pour lequel les algorithmes d'apprentissage automatique excellent. 
	Dans le cadre de notre problème, toutes les espèces présentes sur le site du parc ... sont connues. Le choix se porte donc sur un apprentissage de type supervisé.
	Un algorithme de reseau de neurones à été écrit, mais celui-ci ne permettant pas à ce jour le traitement d'image, la bibliothèque Tensorflow à été utilisée à la place.

	\subsection{Méthodologie de construction d'une base de donné fiable}
		Il aurait été fastidieux d'étiquetter à la main un nombre important d'images de basses résolution.   
		- géoportail (verif autorisation... cé) et extration sur des zones ou la couverture d'espèce est uniforme : res --- images triées en 2
	
	\subsection{entrainement et quelle type de modèle }
		-citer papier , à la main car ici le cas est plus simple mais l'on pourrais généraliser. (difference avec eux)

\section{\'{E}valuation des résultats}
	-évalutation de la complexité 
	-propres résultats
	faire tableau 3 colonnes pour les trois images différentes
	% repéré 
	-comparaison avec les résultats des papiers 

\section{Prolongements envisagables}

	Différents prolongement serait envisagables: 
	-Sensible aux ... séparer préalablement et éventuellement grossiemerement les zones forêstières des zones d'habitation ou  industrielle. Même une route bétonné peut éventuellement altérer les réusltats. batiement/contruction quo fausserait les resultat. 
	De plus obtient qu'un cercle autour des arbres
	-une methode watershed segmentation avec marqueurs que l'on à trouvé pourrait etre envisagble pour delinéer parfaitement les arbres (voir papier) 

	
\nocite{NatesanResNet} %à supprimer après!! 
\bibliographystyle{alpha}
\bibliography{references}

\appendix

	\section{Compléments}
		Lien avec filtre basse fréquence (downsampling, pourqoi?)
		le filtre de gauss retire les hautes fréquences donc permet d' augmenter la fréquence d'échantillonage 'théorme de shannon sans qu'il y ait d'artefacts. 
	
	\section{Résultats}	
		-résultats intermédiare (pyramide de gauss)
		-les deux 
		-douglas seul 
		-feuillus seul
		-echantillon banque fourni pour feuillus
		-echantillon banque fourni pour douglas 
		-echantillon aléatoire parmis des images non deja vus
	
	\section{algorithmes}


a faire : réaliser les tableaux de comparaison, mettre en forme le code 
ecrire les preuves 

\end{document}


